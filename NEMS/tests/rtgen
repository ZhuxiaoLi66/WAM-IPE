#! /usr/bin/env python

import os
import sys
import re
import logging
import random
import pwd
import shutil
import getopt
import StringIO
import socket

def fail(how):
    """!Aborts the program with status 1.  Should only be called
    before produtil.setup.  After that, use usage() instead.

    @returns Never; exits program with status 1."""
    sys.stderr.write('ABORT: %s\n'%(how,))
    exit(1)

RTREWIND_SCRIPT_MEAT=r'''
set --
rocotorewind -c $CYCLE -w workflow.xml -d workflow.db
'''

RTRUN_SCRIPT_MEAT=r'''
verbose=0
loop=MISSING
bad=''
help=NO
sleep_time=300
zero_exit=NO
qoutq_more=''
for arg in "$@" ; do
  case "$arg" in
    -v|--verbose) verbose=$(( verbose + 1 )) ;;
    --step) loop=NO ;;
    --loop) loop=YES ;;
    --help) help=YES ;;
    --zero-exit) zero_exit=YES ;;
    -n) qoutq_more='-n' ;;
    *)
       bad="$arg: invalid argument $bad"
  esac
done
if (( verbose > 0 )) ; then
  sleep_time=$(( sleep_time / 3 ))
fi
if [[ "$loop" == MISSING ]] ; then
  bad="missing argument: --loop or --step must be specified $bad"
fi
if [[ "Q$bad" != Q || "$help" == YES ]] ; then
  echo "Format: rtrun [-v [-v] [-n]] [--loop | --step] [--zero-exit] [--help]" 1>&2
  echo "  -v = verbose mode" 1>&2
  echo "  -n = no colors (disable colors in verbose mode)" 1>&2
  echo "  -v -v = super verbose mode (set -x)" 1>&2
  echo "  --loop = only run one step (default is to loop until done)" 1>&2
  echo "  --zero-exit = always exit with status 0 (intended for CRON jobs)" 1>&2
  echo "Exit statuses:" 1>&2
  echo "   0 = workflow is complete, all jobs succeeded OR --zero-exit was given" 1>&2
  echo "  10 = workflow not yet complete, no jobs have failed" 1>&2
  echo "  20 = workflow not yet complete, some jobs have failed" 1>&2
  echo "  30 = workflow is complete, some jobs failed or were lost" 1>&2
  echo "  99 = corrupt or missing database file" 1>&2
  if [[ "Q$bad" != Q ]] ; then
    echo "ABORT: $bad" 1>&2
    exit 1
  else
    exit 0
  fi
fi
if (( verbose > 1 )) ; then
  echo "ENABLING SUPER-VERBOSE MODE"
  set -x
fi
function log() {
  echo $( date '+%m/%d %H:%M:%SZ' ) rtrun INFO: "$*"
}
function warn() {
  echo $( date '+%m/%d %H:%M:%SZ' ) rtrun WARNING: "$*"
}
function verbose() {
  if (( verbose > 0 )) ; then
    echo $( date '+%m/%d %H:%M:%SZ' ) rtrun INFO: "$*"
  fi
}
unchange=0
last_cycledone=-999
last_lostdead=-999
while [[ 1 == 1 ]] ; do
  log "check dependencies and submit jobs..."
  rocotorun -w workflow.xml -d workflow.db
  verbose "check status..."
  cycledone=$( sqlite3 workflow.db 'SELECT id FROM cycles WHERE done>0' | wc -l )
  lostdead=$( sqlite3 workflow.db 'SELECT taskname FROM jobs WHERE state=="DEAD" OR state=="LOST"' |wc -l)
  if [[ "$cycledone" == "$last_cycledone" && \
        "$lostdead"  == "$last_lostdead" ]] ; then
      unchange=$(( $unchange + 1 ))
  else
      unchange=0
  fi
  last_cycledone=$cycledone
  last_lostdead=$lostdead
  if [[ "$cycledone" != "$last_cycledone" && \
        "$lostdead"  != "$last_lostdead" ]] ; then
    count_since_state_change=$(( count_since_state_change + 1 ))
  fi
  if [[ "$cycledone" -gt 0 ]] ; then
      # Cycle is complete.
      if [[ "$lostdead" -gt 0 ]] ; then
          warn "workflow complete but $lostdead jobs FAILED"
          if [[ "$zero_exit" == YES ]] ; then
              exit 0
          else
              exit 30
          fi
      else
          log "workflow is complete and all jobs succeeded."
          exit 0
      fi
  elif [[ "$loop" == NO ]] ; then
      if [[ "$lostdead" -gt 0 ]] ; then
          warn "workflow not yet complete and $lostdead jobs FAILED"
          if [[ "$zero_exit" == YES ]] ; then
              exit 0
          else
              exit 10
          fi
      else
          log "workflow not yet complete but no jobs have failed."
          if [[ "$zero_exit" == YES ]] ; then
              exit 0
          else
              exit 20
          fi
      fi
  else
      if [[ "$lostdead" -gt 0 ]] ; then
          log "workflow is still running and some jobs are FAILED.  ($lostdead lost or dead jobs)"
      else
          log "workflow is still running and no jobs have failed."
      fi
  fi
  if [[ "$have_qoutq" == YES ]] ; then
      job_count=$( qoutq -UL .queue_state  $qoutq_more -Cd rtgen.$UNIQUE_ID | wc -l )
      if [[ "$verbose" -gt 0 ]] ; then
          verbose "sleep 2"
          sleep 2
          verbose "get queue information"
          qoutq -UL .queue_state $qoutq_more -Cd rtgen.$UNIQUE_ID
      fi
      if [[ "$unchange" -gt 2 && "$job_count" < 1 && "$lostdead" -gt 0 ]] ; then
          log "Jobs have FAILED and no jobs are running or submitted."
          log "This usually means the remaining jobs are dependent"
          log "on the FAILED jobs.  Quitting workflow; please check"
          log "the failed jobs."
          if [[ "$zero_exit" == YES ]] ; then
              exit 0
          else
              exit 20
          fi
      fi
  fi
  log "sleep $sleep_time"
  sleep $sleep_time
done
'''

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Attempt to get the produtil package:
try:
    import produtil.setup
except ImportError as ie:
    altpath=os.path.join(os.path.dirname(os.path.realpath(__file__)),'produtil/ush')
    if not os.path.isdir(altpath):
        fail('%s is missing and produtil is not in PYTHONPATH.  Is your produtil external missing?'%(altpath,))
    sys.path.append(altpath)
    import produtil.setup

import produtil.run, produtil.cluster

from produtil.log import jlogger
from produtil.run import runstr, ExitStatusException, checkrun, batchexe
from produtil.testing.testgen import TestGen
from produtil.testing.utilities import BASELINE, EXECUTION, bashify_string
from produtil.testing.rocoto import RocotoRunner
from produtil.testing.setarith import ArithKeyError

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Utility routines:

TOP_OF_USAGE_MESSAGE='''Syntax: rtgen [options] [subset]

Generates an NCEP three-tier workflow structure to run the specified
regression tests or compsets.  The user must then run some scripts
inside that directory to execute the tests and report the results.
If no subset is requested, all known tests are run.
'''

SHORT_USAGE_MESSAGE=TOP_OF_USAGE_MESSAGE+'''
Run with -h for full instructions.
'''

FULL_USAGE_MESSAGE=TOP_OF_USAGE_MESSAGE+'''
--SUBSETS--
  {gfs_slg,nmm_cntrl} -- run gfs_slg and nmm_cntrl tests
  wam                 -- run all wam tests
  minus(gsm,wam)      -- run all gsm tests except wam tests
  inter(nmm,standard) -- run all standard nmm tests
  union(nmm,wam)      -- run all nmm and gsm tests
Specifications can be nested:
    minus(inter(union(gsm,nmm),standard),{gfs_slg,nmm_cntrl})
  That will run all gsm and nmm tests that are standard tests, except
  for gfs_slg and nmm_cntrl.

--OPTIONS--

  -i all.input
       Path to the input file that specifies the known compsets and
       regression tests.  Default: all.input
  -p avn
       Project for batch submission.  Default: use the project that
       has the most resources available among those the user can
       access.
  -b
       Run in BASELINE mode; generate a baseline instead of verifying
       against an old baseline.  Will disable running of non-baseline
       tests (tests not in the "baseline" subset).
  -v
       Vebose mode
  -d
       Dry run mode; print what would be done without doing it.
  -t /ptmp/$USER
       Path to temporary area.  Default: pick the scratch space with
       the most disk space remaining and append the username.
  -u 12345
       Unique integer id to identify this workflow.  Default: unix
       process id of rtgen
  -n /path/to/baseline
       Use the specified area for the baseline.  If running in baseline
       mode, the baseline template will NOT be copied.  Instead, the
       specified area will be used.

  -S
       Script wrapper mode.  Enables extra output at the end of
       execution to print variables needed by the calling script.
  --
       Terminate option processing.  Remaining arguments are subsets.

  NOTE: Use -n, -t, and -u to regenerate a workflow in the same
        directory as a previous one.
'''


def full_usage():
    print FULL_USAGE_MESSAGE
    sys.exit(0)

def usage(reason):
    sys.stderr.write(SHORT_USAGE_MESSAGE)
    if reason:
        sys.stderr.write('\nSCRIPT IS ABORTING BECAUSE: %s\n'%(reason,))
        exit(1)
    exit(0)

def initial_checks():
    """!Performs basic sanity checks, such as whether some input files
    are present."""
    if not os.path.isfile('produtil/ush/testgen.py'):
        usage('file produtil/ush/testgen.py does not exist.  Are you '
              'missing the produtil external?')
    if not os.path.isdir('../../NEMS/tests'):
        usage('directory ../../NEMS/tests does not exist.  This must '
              'be part of a NEMS app checkout.')

def username():
    """!Returns the current username.  This uses the process's user id
    and the pwent database, hence it is less vulnerable to errors than
    $USER.

    @returns the process's current username"""
    return pwd.getpwuid(os.getuid()).pw_name

def decide_project_theia():
    """!Chooses which project to use when submitting jobs on Theia.

    Uses the account_params program to scan the available core-hours
    on Theia.  Chooses the project with the most available core-hours.
    If no projects have resources, or if some error happens, then
    the "nems" project is used."""
    logger=logging.getLogger('rtgen')
    try:
        account_params=produtil.run.runstr(
            batchexe('account_params'),logger=jlogger)
    except(EnvironmentError,ExitStatusException) as ee:
        logger.warning('Cannot run account_params: '+str(ee))
        logger.warning('Will use project "nems" for cpu hours.')
        return 'nems'
    default_project='nems'
    projects=list()
    projalloc=dict()
    for line in account_params.splitlines():
        # Allocation: 6912 stmp      0.00      0.00        0.00
        m=re.match('^\s*Allocation:\s+(\d+)\s+(\S+)\s+([0-9.]+)',line)
        if not m:
            # skip other lines
            logger.debug('Skip line: '+line.rstrip())
            continue
        gid,name,alloc = m.groups()
        try:
            alloc=float(alloc)
            if name=='nems': alloc/=2
            if not projects:
                default_project=name
            projects.append(name)
            projalloc[name]=alloc
        except (ValueError,TypeError) as vte:
            logger.warning('Cannot parse: '+line.rstrip())
            continue
    if not projects:
        # Parse error or failure of account_params.
        logger.warning('Could not parse account_params output.  Will use default: '+default_project)
        return default_project
    projects.sort(lambda a,b: cmp(projalloc[a],projalloc[b]))
    projchoose=projects[-1]

    if projalloc[projchoose]<1.0:
        logger.warning('All projects passed core-hour limit; will use first project: '+default_project)
        return default_project

    for proj in projects:
        if proj==projchoose:
            chose='<== chosen'
        else:
            chose=''
        logger.info('%10s : %6d %s'%(proj,projalloc[proj],chose))
    return projchoose

def decide_tmp_theia():
    """!Chooses a scratch space to use on Theia, based on how close
    each space is to its quota.

    Uses the pan_df program to check the quota of stmp1 through stmp4.
    Returns the one that is farthest from quota based on percent
    usage.  If this process fails, such as pan_df giving a non-zero
    return status or unparseable output, then a random stmp is chosen.

    @returns path to a temporary directory, which may not yet exist."""
    logger=logging.getLogger('rtgen')
    stmps=[ '/scratch3/NCEPDEV/stmp1',
            '/scratch3/NCEPDEV/stmp2',
            '/scratch4/NCEPDEV/stmp3',
            '/scratch4/NCEPDEV/stmp4' ]
    try:
        args=['-B', '1G', '--' ]
        args.extend(stmps)
        pan_df=produtil.run.runstr(batchexe('pan_df')[args])
        storage=dict()
        for m in re.finditer(r'''(?isx)
            (?:
                 \s* (?P<device>  \S+ )
                 [ \t\r\n]+ (?P<size>    \d+ )
                 \s+ (?P<used>    \d+ )
                 \s+ (?P<avail>   \d+ )
                 \s+ (?P<percent> [0-9.]+ ) %
                 \s+ (?P<mntpnt>  \S+ )
            |
                 (?P<bad> [^\r\n]*[\r\n] | [^\r\n]*\Z ) )
            ''',pan_df):
            # Skip lines that do not have usage information (such as
            # the header line).
            if m.group('bad') or not m.group('mntpnt'):
                logger.debug('pan_df: ignoring %s'%(repr(m.group(0).strip()),))
                continue

            mntpnt=m.group('mntpnt')
            percent=m.group('percent')
            percent=int(percent,10)

            # Skip lines with invalid mount points:
            if not os.path.isdir(mntpnt):
                logger.warning(
                    'Ignoring invalid mount point from pan_df: %s'%(
                        mntpnt,))
                continue

            # Store all valid lines:
            logger.debug('pan_df: %s at %d%% usage'%(mntpnt,percent))
            storage[mntpnt]=percent

        # Return the least used stmp if available.
        if not storage:
            logger.error(
                'No valid lines seen in pan_df output.')
        else:
            by_usage=storage.keys()
            by_usage.sort(
                lambda a,b: cmp(storage[a],storage[b]))
            logger.info('%s: use this tmp (has lowest usage at %d%%)'%(
                    by_usage[0],storage[by_usage[0]]))
            return os.path.join(by_usage[0],username())

    except(EnvironmentError,ExitStatusException,KeyError,ValueError) as e:
        # Log all likely errors before emergency fallback option:
        logger.error(str(e),exc_info=True)

    use_me=random.choice(stmps)
    logger.warning("Auto-detection of least used stmp failed.")
    logger.warning("%s: randomly chosen stmp"%(use_me,))
    return os.path.join(use_me,username())

def decide_project_wcoss1():
    """!Placeholder for future development; returns "GFS-T2O" """
    return 'GFS-T2O'

def decide_tmp_wcoss1():
    """!Placeholder for future development; returns "/ptmpp/$USER"
    where $USER is the username """
    logger=logging.getLogger('rtgen')

    # are we on tide or gyre?
    host=socket.gethostname()
    tg=host[0] # = t for tide or g for gyre

    ptmps=[ [ '/ptmpd1', '-j', 'ptmp-d1', 'gpfs-'+tg+'d1'],
            [ '/ptmpd2', '-j', 'ptmp-d2', 'gpfs-'+tg+'d2'],
            [ '/ptmpp1', '-j', 'ptmp-p1', 'gpfs-'+tg+'p1'] ]
    
    # Area with maximum space available and available space in TB:
    max_area='/ptmpp1'   # default value on failure
    max_avail=0

    for ptmp in ptmps:
        try:
            args=['/usr/lpp/mmfs/bin/mmlsquota', '--block-size', '1T' ]
            args.extend(ptmp[1:])
            area=ptmp[0]
            cmd=batchexe(args[0])[args[1:]]
            mmlsquota=produtil.run.runstr(cmd,logger=logger)
            if not mmlsquota:
                logger.error('mmlsquota printed nothing')
                continue
            
            #gpfs-gd1 FILESET 19 147 147 1 none | 1399932 0 0 158 none 
            #                 ^      ^
            #                 |      +--- TB Limit
            #                 +---------- TB Used

            for m in re.finditer(r'''(?isx)
               (?:
                   \S+ \s+ FILESET
                   \s+ (?P<TBused>  \d+  )
                   \s+ (?P<TBquota> \d+  )
                   \s+ (?P<TBlimit> \d+  )
                   [^\r\n]* (?: [\r\n] | [\r\n]*\Z )
                |
                 (?P<bad> [^\r\n]*[\r\n] | [^\r\n]*\Z )
               )
               ''',mmlsquota):

                if m.group('bad') or not m.group('TBused') \
                        or not m.group('TBlimit'):
                    logger.debug('mmlsquota: ignoring %s'%(
                            repr(m.group(0).strip()),))
                    continue
                avail=int(m.group('TBlimit')) - int(m.group('TBused'))
                logger.info('%s: %d TB available'%(area,avail))
                if avail>max_avail:
                    logger.info('Higher than %s: %d TB available'%(max_area,max_avail))
                    ( max_area, max_avail) = ( area, avail )
        except(EnvironmentError,ExitStatusException,KeyError,ValueError) as e:
            # Log all likely errors before emergency fallback option:
            logger.error(str(e),exc_info=True)

    if max_area:
        logger.info('%s: use this ptmp with %d TB available'%(
                max_area,max_avail))
    else:
        logger.warning('Auto-detection of least used ptmp failed.')
        logger.warning('Will fall back to %s'%(max_area,))

    return os.path.join(max_area,username())

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Custom test generator:

class RTGen(TestGen):
    def __init__(self,baseline,scratch_dir,unique_id=None,
                 logger=None,baseline_dir=None,
                 verbose=True,dry_run=False,inputfile=None,
                 setarith=None,project=None):
        baseline=bool(baseline)
        self.no_copy_template = baseline_dir is not None
        if unique_id is None:
            unique_id=os.getpid()
        scratch_dir=os.path.join(scratch_dir,'rtgen.%d'%unique_id)
        outloc=scratch_dir
        self.test_path=outloc
        super(RTGen,self).__init__(
            BASELINE if baseline else EXECUTION,
            RocotoRunner,outloc,inputfile,dry_run,unique_id,
            logger=logger,verbose=verbose,setarith=setarith)
        self._scratch_dir=scratch_dir
        self._new_baseline=baseline_dir
        if baseline and not self._new_baseline:
            self._new_baseline=os.path.join(
                self._scratch_dir,'REGRESSION_TEST')
        self.platform_name=None
        self.project=project
        assert(project)
        assert(self.project)
    def override(self,scope):
        assert(self.project)
        self._scope=scope
        if self._new_baseline:
            scope.override_local([scope],'plat%BASELINE',self._new_baseline)
        if self.project:
            self.logger.warning('override project with '+self.project)
            scope.override_local([scope],'plat%CPU_ACCOUNT',self.project)
            scope.override_local([scope],'plat%ACCOUNT',self.project)
        else:
            raise Exception('no project')
    @property
    def new_baseline(self):
        return self._new_baseline
    def make_vars(self):
        morevars=super(RTGen,self).make_vars()
        morevars['RT_SCRATCH_DIR']=self._scratch_dir
        return morevars
    def make_more(self,result,con):
        self.platform_name=self.scope.resolve('plat%PLATFORM_NAME') \
                               .string_context(con)
        self.make_rtrun()
        self.make_rtrewind()
        self.make_rtreport()
        #if self._new_baseline:
        #    self.make_baseline_dir()
    def make_bash_load_rocoto(self,out):
        here=produtil.cluster.where()
        out.write('#!/usr/bin/env bash\n\n')
        out.write('UNIQUE_ID=%d\n'%(self.unique_id,))
        if here.name in [ 'tide', 'gyre' ]:
            out.write('module load lsf\n')
            out.write('module use /hwrf/noscrub/soft/modulefiles\n')
            out.write('module load rocoto\n')
            out.write('module load ruby # workaround for libxml2 bug\n')
            out.write('module load emc-utils ; have_qoutq=YES\n')
        elif here.name in [ 'surge', 'luna' ]:
            out.write('module load xt-lsfhpc\n')
            out.write('module use /gpfs/hps/emc/hwrf/noscrub/soft/modulefiles\n')
            out.write('module load rocoto\n')
            out.write('module load emc-utils ; have_qoutq=YES\n')
        elif here.name == 'theia':
            out.write('module load rocoto\n')
            out.write('module use /scratch3/NCEPDEV/hwrf/save/Samuel.Trahan/emc-utils/modulefiles/\n')
            out.write('module load hpss emc-utils ; have_qoutq=YES\n')
        else:
            out.write('have_qoutq=NO\n')
        out.write('work=%s/rocoto\n'%(bashify_string(self.outloc),))
        out.write('cd "$work"\n')
        out.write('if [[ "$?" != 0 ]] ; then\n')
        out.write('  echo "$work: cannot cd"\n')
        out.write('  exit 2\n')
        out.write('fi\n')
    def make_rtscript(self,path,name,contents):
        fullpath=os.path.join(path,name)
        self.logger.info('%s: write %s script'%(fullpath,name))
        if not self.dry_run:
            with open(fullpath,'wt') as rtrun:
                rtrun.write(contents)
        self.logger.info('%s: make executable'%(fullpath,))
        if not self.dry_run:
            os.chmod(fullpath,0755)
    def make_rtreport(self):
        out=StringIO.StringIO()
        self.make_bash_load_rocoto(out)
        out.write(r'''
rocotostat -w workflow.xml -d workflow.db -c ALL > rocotostat.txt
timestamp=$( ls -l --time=c --time-style=+%%s workflow.xml | awk '{print $6}' )
%s/rtreportimpl ../com rocotostat.txt "${1:-txt}" $timestamp > rtreport.txt
cat rtreport.txt
'''%(bashify_string(os.path.realpath(os.path.dirname(__file__))),))
        self.make_rtscript(self.outloc,'rtreport',out.getvalue())
        out.close()
    def make_rtrewind(self):
        out=StringIO.StringIO()
        self.make_bash_load_rocoto(out)
        out.write(r'''
if [[ "$#" -lt 1 ]] ; then
    echo 'Synopsis:'
    echo '  Instructs Rocoto to rerun some tests or builds.'
    echo ' '
    echo 'Format:'
    echo '  Rewind all tasks: rtrewind -a'
    echo '  Rewind some tasks: rtrewind taskname [ taskname [... ] ]'
    echo ' '
    echo 'Where "taskname" is the build or test name, minus the'
    echo '"build_" or "test_" part.  Examples:'
    echo '  Recompile gsm.x and nmm.x:  rtrewind gsm.x nmm.x'
    echo '  Recompile and rerun everything: rtrewind -a'
    echo ' '
    echo 'Note: make sure you rewind any tasks that depend on your rewound task.'
    exit 1
fi
set -x
command=$( rocotostat -w workflow.xml -d workflow.db -c ALL | \
    %s/rtrewindimpl "$@" )
$command
'''%(bashify_string(os.path.realpath(os.path.dirname(__file__))),))
        self.make_rtscript(self.outloc,'rtrewind',out.getvalue())
        out.close()
    def make_rtrun(self):
        out=StringIO.StringIO()
        self.make_bash_load_rocoto(out)
        out.write(RTRUN_SCRIPT_MEAT)
        self.make_rtscript(self.outloc,'rtrun',out.getvalue())
        out.close()
    def make_baseline_dir(self):
        if self.no_copy_template: return
        template=self.scope.resolve('plat%BASELINE_TEMPLATE') \
            .string_context(self.parser.con())
        if os.path.exists(self.new_baseline):
            jlogger.info('%s: delete tree'%(self.new_baseline,))
            shutil.rmtree(self.new_baseline)
        jlogger.info('%s: copy from %s'%(
                self.new_baseline,template))
        shutil.copytree(template,self.new_baseline,symlinks=True)

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Main program:

def parse_arguments():
    try:
        optval,arglist=getopt.getopt(sys.argv[1:],'vdu:t:bn:i:p:hS')
    except getopt.GetoptError as ge:
        usage(str(ge))
    verbose=0
    dry_run=False
    unique_id=int(os.getpid())
    temp=None
    baseline=False
    baseline_dir=None
    inputfile=None
    project=None
    script_mode=False
    for opt,val in optval:
        if opt=='-v':
            verbose+=1
        elif opt=='-h':
            full_usage() # does not return
        elif opt=='-p':
            project=val
        elif opt=='-d':
            dry_run=True
        elif opt=='-n':
            baseline_dir=val
        elif opt=='-u':
            unique_id=int(val,10)
        elif opt=='-t':
            temp=str(val)
        elif opt=='-b':
            baseline=True
        elif opt=='-i':
            inputfile=val
        elif opt=='-S':
            script_mode=True
        else:
            usage('unknown option '+opt)
    arglist_nowhite=list() # arguments that are not whitespace
    for arg in arglist:
        if not re.match('(?sx) \A \s* \Z',arg):
            arglist_nowhite.append(arg)
    return verbose,baseline_dir,dry_run,baseline,unique_id,temp, \
           inputfile,arglist_nowhite,project,script_mode

########################################################################

def verify_fingerprint(baseline,testgen,logger):
    if baseline:
        baseline_fingerprint=os.path.join(
            testgen.get_string('plat%BASELINE_TEMPLATE'),
            'REGTEST-FINGERPRINT.md')
    else:
        baseline_fingerprint=os.path.join(
            testgen.get_string('plat%BASELINE'),
            'REGTEST-FINGERPRINT.md')
    repo_fingerprint=os.path.join(
        testgen.get_string('plat%PARMnems'),
        'REGTEST-FINGERPRINT.md')

    with open(baseline_fingerprint,'r') as base_finger_file:
        base_finger_dat=base_finger_file.read()

    with open(repo_fingerprint,'r') as repo_finger_file:
        repo_finger_dat=repo_finger_file.read()

    if repo_finger_dat != base_finger_dat:
        jlogger.error('You are using the wrong data directory.')
        jlogger.error('Baseline finger print does not match repo fingerprint.')
        jlogger.error('  Baseline fingerprint file: %s'%(
                baseline_fingerprint,))
        jlogger.error('  Repository fingerprint file: %s'%(
                repo_fingerprint,))
        sys.exit(1)
    else:
        jlogger.info('Baseline fingerprint matches repo fingerprint. Rejoice.')
        jlogger.info('  Baseline fingerprint file: %s'%(
                baseline_fingerprint,))
        jlogger.info('  Repository fingerprint file: %s'%(
                repo_fingerprint,))

########################################################################

def main():
    verbose,baseline_dir,dry_run,baseline,unique_id,temp, \
        inputfile,arglist,project,script_mode = \
            parse_arguments()
    assert(isinstance(unique_id,int))

    if len(arglist)>1:
        arith='union('+','.join(arglist)+')'
    elif arglist:
        arith=arglist[0]
    else:
        arith=None

    if baseline:
        if arith:
            arith='inter(baseline,%s)'%(arith,)
        else:
            arith='baseline'

    # Initialize the produtil package.
    produtil.setup.setup(
        send_dbn=False,   # avoids "dbnalert missing" warnings
        jobname='rtgen',  # set job name for jlogfile messages
        ologlevel=logging.INFO if verbose else logging.WARNING)
    logger=logging.getLogger('rtgen')

    if arith is None:
        jlogger.info('Will run all known tests.')
    else:
        jlogger.info('Test suite subset = %s'%(arith,))

    if project is None:
        if produtil.cluster.name() == 'theia':
            project=decide_project_theia()
        elif produtil.cluster.name() in ['gyre','tide'] and \
                produtil.cluster.where().wcoss_phase == 1:
            project=decide_project_wcoss1()
        else:
            fail('Unknown system.  Only Theia and WCOSS Phase 1 are supported.')
        jlogger.info('Auto-chosen project for job submission is %s'%(
                repr(project),))
    else:
        jlogger.info('User-provided project for job submission is %s'%(
                repr(project),))

    if temp is None:
        if produtil.cluster.name() == 'theia':
            scratch_dir=decide_tmp_theia()
        elif produtil.cluster.name() in ['gyre','tide'] and \
                produtil.cluster.where().wcoss_phase == 1:
            scratch_dir=decide_tmp_wcoss1()
        else:
            fail('Unknown system.  Only Theia and WCOSS Phase 1 are supported.')
        jlogger.info('Auto-chosen ptmp is %s'%(repr(scratch_dir),))
    else:
        scratch_dir=temp
        jlogger.info('User-provided ptmp is %s'%(repr(scratch_dir),))

    if inputfile is None:
        for path in [ '../../compsets/all.input','compsets/all.input',
                      '../compsets/all.input' ]:
            if os.path.isfile(path):
                inputfile=path
    if inputfile is None:
        usage('file all.input is missing.  You must run this script from '
              'one of these directories: app-level, NEMS or NEMS/tests.')

    testgen=RTGen(baseline,scratch_dir,unique_id,logger,
                  baseline_dir,inputfile=inputfile,
                  verbose=bool(verbose),dry_run=dry_run,
                  setarith=arith,project=project)

    jlogger.info('Parsing compset descriptions.')
    testgen.parse()

    jlogger.info('Verifying repo fingerprint against data fingerprint.')
    verify_fingerprint(baseline,testgen,logger)

    try:
        jlogger.info('Generating workflow with id %s.'%(repr(unique_id),))
        testgen.generate()
    except ArithKeyError as ake:
        # User specified an invalid set or test.  Give the usage message.
        usage(str(ake))
    except Exception as e:
        # Complain about errors in the jlogfile and exit with status 1.

        # Note that this will not catch high-level errors such as
        # signals or exit.  That is deliberate, for safety reasons.
        produtil.log.jlogger.error(str(e),exc_info=True)
        exit(1)
    # We get here if everything works.
    jlogger.info('Requested test has been generated.')
    if script_mode:
        print "RUNDIR='%s' ; PLATFORM_NAME='%s'"%(
            testgen.outloc, testgen.platform_name)
    else:
        print r'''You need to run the test now.   You have three options:
OPTION 1: Put this in your cron:
  */3 * * * * %s/rtrun --step --zero-exit > %s/rtrun-cron.log 2>&1

OPTION 2: Run this program:
  %s/rtrun --loop

OPTION 3: Verbose mode: run this program:
  %s/rtrun -v --loop
Adding -n to that command will disable colors.
'''%(
        testgen.outloc,
        testgen.outloc,
        testgen.outloc,
        testgen.outloc)
    # Last line must print the RUNDIR= for calling process
    exit(0)

if __name__=='__main__':
    main()
